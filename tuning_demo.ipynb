{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune Hugging Face BERT with PyTorch Lightning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following cells will train the model using settings that are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:27:36.499323Z",
     "start_time": "2024-12-20T09:27:29.214207Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import CSVLogger, CometLogger, TensorBoardLogger\n",
    "from lightning.pytorch.profilers import PyTorchProfiler\n",
    "\n",
    "from dvclive.lightning import DVCLiveLogger\n",
    "\n",
    "from datamodule import AutoTokenizerDataModule\n",
    "from module import CustomModel, LinearBAModel, LinearBEModel\n",
    "from utils import create_dirs\n",
    "from config import Config, DataModuleConfig, ModuleConfig\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:27:36.530795Z",
     "start_time": "2024-12-20T09:27:36.511327Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 59631546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59631546"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(59631546)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:27:36.624317Z",
     "start_time": "2024-12-20T09:27:36.609675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42eefcb3125844048a9664046d0a51ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "token = os.getenv('HUG_FACE_TOKEN')\n",
    "login(token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's configure some basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:27:36.654297Z",
     "start_time": "2024-12-20T09:27:36.641318Z"
    }
   },
   "outputs": [],
   "source": [
    "# model and dataset\n",
    "model_name = ModuleConfig.model_name\n",
    "max_length = ModuleConfig.max_length\n",
    "lr = ModuleConfig.learning_rate\n",
    "dataset_name = DataModuleConfig.dataset_name\n",
    "batch_size = DataModuleConfig.batch_size\n",
    "\n",
    "# paths\n",
    "cache_dir = Config.cache_dir\n",
    "log_dir = Config.log_dir\n",
    "ckpt_dir = Config.ckpt_dir\n",
    "prof_dir = Config.prof_dir\n",
    "perf_dir = Config.perf_dir\n",
    "# creates dirs to avoid failure if empty dir has been deleted\n",
    "create_dirs([cache_dir, log_dir, ckpt_dir, prof_dir, perf_dir])\n",
    "\n",
    "# set matmul precision\n",
    "# see https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:27:36.685688Z",
     "start_time": "2024-12-20T09:27:36.670684Z"
    }
   },
   "outputs": [],
   "source": [
    "class LoRACheckpoint(ModelCheckpoint):\n",
    "    def _save_checkpoint(self, trainer: pl.Trainer, filepath: str) -> None:\n",
    "        # trainer.save_checkpoint(filepath, self.save_weights_only)\n",
    "        trainer.lightning_module.encoder.encoder.save_pretrained(filepath)  # 保存するモデルのパスを指定\n",
    "\n",
    "        self._last_global_step_saved = trainer.global_step\n",
    "        self._last_checkpoint_saved = filepath\n",
    "\n",
    "        # notify loggers\n",
    "        #if trainer.is_global_zero:\n",
    "        #    for logger in trainer.loggers:\n",
    "        #        logger.after_save_checkpoint(proxy(self))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define our LightningDataModule, which will be used by Trainer for its DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:27:36.717692Z",
     "start_time": "2024-12-20T09:27:36.702691Z"
    }
   },
   "outputs": [],
   "source": [
    "lit_datamodule = AutoTokenizerDataModule(\n",
    "    model_name=model_name,\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,\n",
    "    batch_size=batch_size,\n",
    "    max_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:27:36.748695Z",
     "start_time": "2024-12-20T09:27:36.733696Z"
    }
   },
   "outputs": [],
   "source": [
    "lit_datamodule.clear_custom_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:27:45.202154Z",
     "start_time": "2024-12-20T09:27:36.766458Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 59631546\n",
      "[2025-03-03 16:31:35.157962] Data cache exists. Loading from cache.\n"
     ]
    }
   ],
   "source": [
    "lit_datamodule.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:27:59.765808Z",
     "start_time": "2024-12-20T09:27:45.219157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text', 'non_disaster', 'disaster', 'flood', 'extreme_rain', 'earthquake', 'typhoon', 'landslide', 'tsunami', 'volcano', 'wildfire', 'informative', 'non_informative'],\n",
      "        num_rows: 3660\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'text', 'non_disaster', 'disaster', 'flood', 'extreme_rain', 'earthquake', 'typhoon', 'landslide', 'tsunami', 'volcano', 'wildfire', 'informative', 'non_informative'],\n",
      "        num_rows: 914\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "lit_datamodule.setup(\"fit\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and our custom LightningModule with ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:27:59.797812Z",
     "start_time": "2024-12-20T09:27:59.783810Z"
    }
   },
   "outputs": [],
   "source": [
    "#lit_datamodule.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:00.544848Z",
     "start_time": "2024-12-20T09:27:59.816120Z"
    }
   },
   "outputs": [],
   "source": [
    "lit_model = CustomModel(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_linear_model = LinearBAModel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next - we are going to define some common callbacks, and our most basic logger - CSVLogger.\n",
    "\n",
    "EarlyStopping callback helps us to end training early if a convergence criteria is met before the max-iteration setting is reached.\n",
    "\n",
    "ModelCheckpoint saves the model periodically, and after training finishes, uses best_model_path to retrieve the path to the best checkpoint file and best_model_score to retrieve its score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:00.574589Z",
     "start_time": "2024-12-20T09:28:00.560356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    ModelCheckpoint(\\n        dirpath=ckpt_dir,\\n        monitor=\"val_f1\",\\n        filename=\"model\",\\n        save_top_k=3,\\n        mode=\"max\",\\n        save_weights_only=True,\\n    ),\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    ModelCheckpoint(\n",
    "        dirpath=ckpt_dir,\n",
    "        monitor=\"val_f1\",\n",
    "        filename=\"model\",\n",
    "        save_top_k=3,\n",
    "        mode=\"max\",\n",
    "        save_weights_only=True,\n",
    "    ),\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:00.605592Z",
     "start_time": "2024-12-20T09:28:00.591592Z"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_f1\", mode=\"max\", patience=3),\n",
    "    ModelCheckpoint(\n",
    "        dirpath=ckpt_dir,\n",
    "        monitor=\"val_f1\",\n",
    "        filename=\"model\",\n",
    "        save_top_k=3,\n",
    "        mode=\"max\",\n",
    "        save_weights_only=True,\n",
    "    ),\n",
    "\n",
    "    LearningRateMonitor(logging_interval='step'),\n",
    "\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:00.668166Z",
     "start_time": "2024-12-20T09:28:00.653250Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = CSVLogger(\n",
    "    save_dir=log_dir,\n",
    "    name=\"csv-logs\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally – we create our Trainer and pass in our flags (settings), the callbacks and loggers.  Then we call fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:00.698529Z",
     "start_time": "2024-12-20T09:28:00.685235Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_seed():\n",
    "    torch_init_seed = torch.initial_seed()\n",
    "    torch_cuda_seed = torch.cuda.initial_seed()\n",
    "    numpy_seed = np.random.get_state()[1][0]\n",
    "\n",
    "    print(f\"pytorch seed: {torch_init_seed}\")\n",
    "    print(f\"cuda seed: {torch_cuda_seed}\")\n",
    "    print(f\"numpy seed: {numpy_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:00.729976Z",
     "start_time": "2024-12-20T09:28:00.714834Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 59631546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59631546"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(59631546)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:00.775423Z",
     "start_time": "2024-12-20T09:28:00.746487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch seed: 59631546\n",
      "cuda seed: 59631546\n",
      "numpy seed: 59631546\n"
     ]
    }
   ],
   "source": [
    "print_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:01.011199Z",
     "start_time": "2024-12-20T09:28:00.793475Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in online mode\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'callbacks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m lit_trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m      2\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m16-mixed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m      7\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m     logger\u001b[38;5;241m=\u001b[39m[logger, CometLogger(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msbmb8Cxs9NXSzPzAyzpudsVlM\u001b[39m\u001b[38;5;124m\"\u001b[39m), DVCLiveLogger(save_dvc_exp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)],\n\u001b[1;32m----> 9\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[43mcallbacks\u001b[49m,\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'callbacks' is not defined"
     ]
    }
   ],
   "source": [
    "lit_trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    strategy=\"auto\",\n",
    "    precision=\"16-mixed\",\n",
    "    max_epochs=8,\n",
    "    deterministic=True,\n",
    "    logger=[logger, CometLogger(api_key=\"YOUR_COMET_API_KEY\"), DVCLiveLogger(save_dvc_exp=True)],\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:01.042406Z",
     "start_time": "2024-12-20T09:28:01.028884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (encoder): BERTEmbeeding(\n",
       "    (encoder): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(250002, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (distance_embedding): Embedding(1023, 64)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): LSTMClassificationHEAD(\n",
       "    (lstm): LSTM(768, 768, batch_first=True)\n",
       "    (linear): Linear(in_features=768, out_features=12, bias=True)\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       "  (accuracy): MultilabelAccuracy()\n",
       "  (precision): MultilabelPrecision()\n",
       "  (recall): MultilabelRecall()\n",
       "  (f1_score): MultilabelF1Score()\n",
       "  (macro_f1_score): MultilabelF1Score()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:01.135485Z",
     "start_time": "2024-12-20T09:28:01.122485Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:01.166533Z",
     "start_time": "2024-12-20T09:28:01.152178Z"
    }
   },
   "outputs": [],
   "source": [
    "#lit_trainer.fit(model=lit_model, datamodule=lit_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:06:52.915528Z",
     "start_time": "2024-12-20T09:06:48.997523Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CustomModel:\n\tMissing key(s) in state_dict: \"classifier.lstm.weight_ih_l0\", \"classifier.lstm.weight_hh_l0\", \"classifier.lstm.bias_ih_l0\", \"classifier.lstm.bias_hh_l0\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43me:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mBEST-bart-liner\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodel-v35.ckpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\syc\\anaconda3\\envs\\tw-ai\\lib\\site-packages\\lightning\\pytorch\\core\\module.py:1543\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[0;32m   1465\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1471\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1543\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m _load_from_checkpoint(\n\u001b[0;32m   1544\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   1545\u001b[0m         checkpoint_path,\n\u001b[0;32m   1546\u001b[0m         map_location,\n\u001b[0;32m   1547\u001b[0m         hparams_file,\n\u001b[0;32m   1548\u001b[0m         strict,\n\u001b[0;32m   1549\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1550\u001b[0m     )\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[1;32mc:\\Users\\syc\\anaconda3\\envs\\tw-ai\\lib\\site-packages\\lightning\\pytorch\\core\\saving.py:91\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[1;32m---> 91\u001b[0m     model \u001b[38;5;241m=\u001b[39m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, strict\u001b[38;5;241m=\u001b[39mstrict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "File \u001b[1;32mc:\\Users\\syc\\anaconda3\\envs\\tw-ai\\lib\\site-packages\\lightning\\pytorch\\core\\saving.py:157\u001b[0m, in \u001b[0;36m_load_state\u001b[1;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m strict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys\u001b[38;5;241m.\u001b[39mmissing_keys:\n",
      "File \u001b[1;32mc:\\Users\\syc\\anaconda3\\envs\\tw-ai\\lib\\site-packages\\torch\\nn\\modules\\module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CustomModel:\n\tMissing key(s) in state_dict: \"classifier.lstm.weight_ih_l0\", \"classifier.lstm.weight_hh_l0\", \"classifier.lstm.bias_ih_l0\", \"classifier.lstm.bias_hh_l0\". "
     ]
    }
   ],
   "source": [
    "model = lit_model.load_from_checkpoint(\"./checkpoints/best.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ba_linear_model.load_from_checkpoint(r\"e:\\BEST-bart-linear\\model-v35.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:05.330578Z",
     "start_time": "2024-12-20T09:28:05.317448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinerBAModel(\n",
       "  (encoder): BARTEmbeddings(\n",
       "    (encoder): BartModel(\n",
       "      (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "      (encoder): BartEncoder(\n",
       "        (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x BartEncoderLayer(\n",
       "            (self_attn): BartSdpaAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): BartDecoder(\n",
       "        (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x BartDecoderLayer(\n",
       "            (self_attn): BartSdpaAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartSdpaAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): BertLinearClassificationHead(\n",
       "    (linear): Linear(in_features=1024, out_features=12, bias=True)\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       "  (accuracy): MultilabelAccuracy()\n",
       "  (precision): MultilabelPrecision()\n",
       "  (recall): MultilabelRecall()\n",
       "  (f1_score): MultilabelF1Score()\n",
       "  (macro_f1_score): MultilabelF1Score()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:28:05.299Z",
     "start_time": "2024-12-20T09:28:01.183687Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at Twitter/twhin-bert-base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at Twitter/twhin-bert-base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = lit_model.load_from_checkpoint(r\"C:\\Users\\syc\\Downloads\\best-0.8833.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lit_model.load_from_checkpoint(r\"C:\\Users\\syc\\Downloads\\model-v235-0.9606.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:29:02.890420Z",
     "start_time": "2024-12-20T09:28:53.092671Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lit_trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#lit_trainer.validate(model=model, datamodule=lit_datamodule)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Run validation\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# results = lit_trainer.validate(model=model, datamodule=lit_datamodule)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mlit_trainer\u001b[49m\u001b[38;5;241m.\u001b[39mvalidate(model\u001b[38;5;241m=\u001b[39mmodel, datamodule\u001b[38;5;241m=\u001b[39mlit_datamodule)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lit_trainer' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#lit_trainer.validate(model=model, datamodule=lit_datamodule)\n",
    "# Run validation\n",
    "# results = lit_trainer.validate(model=model, datamodule=lit_datamodule)\n",
    "results = lit_trainer.validate(model=model, datamodule=lit_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:29:31.811203Z",
     "start_time": "2024-12-20T09:29:31.796335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.1585824191570282,\n",
       "  'val_accuracy': 0.9458422064781189,\n",
       "  'val_precision': 0.8862585425376892,\n",
       "  'val_recall': 0.88088458776474,\n",
       "  'val_f1': 0.8830068707466125,\n",
       "  'val_macro_f1': 0.5132007598876953}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:29:35.194568Z",
     "start_time": "2024-12-20T09:29:35.113057Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true = [label for batch in lit_datamodule.val_dataloader() for label in batch[\"label\"].numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:29:35.320641Z",
     "start_time": "2024-12-20T09:29:35.313641Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:29:36.007845Z",
     "start_time": "2024-12-20T09:29:35.570526Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:29:38.372682Z",
     "start_time": "2024-12-20T09:29:36.155680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4db0fb64b654db595b9317e8382bf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "from tqdm.notebook import tqdm\n",
    "# Prepare list for storing inf results\n",
    "y_pred = []\n",
    "\n",
    "# Disable grad for inf\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(lit_datamodule.val_dataloader()):\n",
    "        #print(batch)\n",
    "        input_ids = batch[model.input_key].to(model.device)\n",
    "        attention_mask = batch[model.mask_key].to(model.device)\n",
    "        #token_type_ids = batch[\"token_type_ids\"]\n",
    "        \n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        #print(torch.sigmoid(logits[:, 1]))\n",
    "        preds = (torch.sigmoid(logits)> 0.5).int()\n",
    "\n",
    "        y_pred.extend(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:29:38.931746Z",
     "start_time": "2024-12-20T09:29:38.921745Z"
    }
   },
   "outputs": [],
   "source": [
    "label_order = [\n",
    "    \"non_disaster\",\n",
    "    \"disaster\",\n",
    "    \"flood\",\n",
    "    \"extreme_rain\",\n",
    "    \"earthquake\",\n",
    "    \"typhoon\",\n",
    "    \"landslide\",\n",
    "    \"tsunami\",\n",
    "    \"volcano\",\n",
    "    \"wildfire\",\n",
    "    \"informative\",\n",
    "    \"non_informative\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:29:39.694271Z",
     "start_time": "2024-12-20T09:29:39.669188Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syc\\anaconda3\\envs\\tw-ai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=label_order, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T09:29:40.828827Z",
     "start_time": "2024-12-20T09:29:40.814827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   non_disaster     0.8045    0.7701    0.7869       187\n",
      "       disaster     0.9374    0.9490    0.9432       726\n",
      "          flood     0.8611    0.8212    0.8407       151\n",
      "   extreme_rain     0.8429    0.9516    0.8939        62\n",
      "     earthquake     0.9167    0.8627    0.8889        51\n",
      "        typhoon     0.9091    0.8889    0.8989        90\n",
      "      landslide     0.9333    0.7368    0.8235        57\n",
      "        tsunami     0.8125    0.9286    0.8667        28\n",
      "        volcano     0.8571    0.7895    0.8219        38\n",
      "       wildfire     0.9599    0.9359    0.9477       281\n",
      "    informative     0.8559    0.8996    0.8772       548\n",
      "non_informative     0.8333    0.7756    0.8034       361\n",
      "\n",
      "      micro avg     0.8876    0.8814    0.8845      2580\n",
      "      macro avg     0.8770    0.8591    0.8661      2580\n",
      "   weighted avg     0.8876    0.8814    0.8837      2580\n",
      "    samples avg     0.8826    0.8765    0.8771      2580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
